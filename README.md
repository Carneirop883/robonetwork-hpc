RoboNetwork HPC

Pipeline profissional de treino, avaliaÃ§Ã£o e exportaÃ§Ã£o de modelos de Machine Learning em ambiente HPC, desenhado para clusters com SLURM, containers Apptainer/Singularity e aceleraÃ§Ã£o GPU (CUDA).

Este repositÃ³rio contÃ©m apenas cÃ³digo, definiÃ§Ãµes e jobs.
Artefactos pesados (containers .sif, datasets, outputs) sÃ£o geridos fora do Git, conforme boas prÃ¡ticas HPC.

VisÃ£o geral

O objetivo deste projeto Ã© fornecer uma base limpa, reprodutÃ­vel e escalÃ¡vel para:

Treino de modelos PyTorch em HPC

ExecuÃ§Ã£o de jobs SLURM de forma controlada

SeparaÃ§Ã£o clara entre:

cÃ³digo

definiÃ§Ã£o de containers

execuÃ§Ã£o

outputs

O pipeline foi pensado para funcionar em ambientes como:

Deucalion / EuroHPC

clusters acadÃ©micos ou industriais

infraestruturas on-prem com SLURM

Estrutura do repositÃ³rio
robonetwork-hpc/
â”œâ”€â”€ containers/
â”‚   â””â”€â”€ base.def                # DefiniÃ§Ã£o do container (Apptainer/Singularity)
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ build_base_container.slurm
â”‚   â”œâ”€â”€ create_torch_env.slurm
â”‚   â”œâ”€â”€ train.slurm
â”‚   â”œâ”€â”€ evaluate.slurm
â”‚   â”œâ”€â”€ export.slurm
â”‚   â””â”€â”€ test_gpu.slurm
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ export_model.py
â”‚
â”œâ”€â”€ test_pytorch_container.slurm
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

PrincÃ­pios do projeto

Git sÃ³ para texto e definiÃ§Ãµes

.py, .slurm, .def

Nunca versionar binÃ¡rios

.sif, datasets, checkpoints, outputs

Reprodutibilidade

containers gerados a partir de .def

SeparaÃ§Ã£o clara de responsabilidades

scripts â‰  jobs â‰  containers

Containers
DefiniÃ§Ã£o

Os containers sÃ£o definidos em:

containers/base.def


Este ficheiro descreve:

base CUDA

dependÃªncias do sistema

Python / PyTorch

bibliotecas necessÃ¡rias ao treino

Build (fora do Git)

O build do container Ã© feito via SLURM:

sbatch jobs/build_base_container.slurm


O resultado serÃ¡ um ficheiro .sif, por exemplo:

cuda_base.sif


ğŸ“Œ Nota importante
Os ficheiros .sif:

nÃ£o entram no Git

vivem no filesystem do cluster (ex: /projects/...)

ou em storage externo (S3, MinIO, etc.)

Jobs SLURM

Todos os jobs estÃ£o na pasta jobs/.

Teste de GPU
sbatch jobs/test_gpu.slurm


Verifica:

acesso a GPU

CUDA disponÃ­vel

PyTorch funcional

Treino
sbatch jobs/train.slurm


Executa:

scripts/train.py

usando o container definido

com recursos controlados por SLURM

AvaliaÃ§Ã£o
sbatch jobs/evaluate.slurm


Executa:

scripts/evaluate.py

sobre um modelo treinado

ExportaÃ§Ã£o
sbatch jobs/export.slurm


Executa:

scripts/export_model.py

exporta o modelo para formato final (ex: .pt, .onnx)

Scripts Python

Os scripts vivem em scripts/ e devem ser:

independentes do SLURM

independentes do cluster

fÃ¡ceis de testar localmente (quando possÃ­vel)

train.py

ResponsÃ¡vel por:

carregar dados

treinar o modelo

guardar checkpoints

evaluate.py

ResponsÃ¡vel por:

avaliar mÃ©tricas

gerar resultados de validaÃ§Ã£o

export_model.py

ResponsÃ¡vel por:

converter/exportar modelos treinados

preparar artefactos finais

Estrutura recomendada (fora do Git)

Estas pastas nÃ£o devem ser versionadas, mas sÃ£o recomendadas no cluster:

datasets/
models/
outputs/
logs/


Normalmente localizadas em:

/projects/<project_id>/robonetwork/

Boas prÃ¡ticas adotadas

Containers reprodutÃ­veis

Jobs isolados e explÃ­citos

HistÃ³rico Git limpo

EscalÃ¡vel para mÃºltiplos modelos e experiÃªncias

Preparado para automaÃ§Ã£o futura
