{
  "name": "PPO",
  "label": "Proximal Policy Optimization",
  "description": "Stable on-policy reinforcement learning algorithm widely used for robotics and humanoid control.",
  "type": "on_policy",

  "params": {
    "clip_range": {
      "type": "float",
      "label": "Clip Range",
      "description": "Clipping parameter for policy updates.",
      "min": 0.01,
      "max": 0.4,
      "default": 0.2
    },

    "gae_lambda": {
      "type": "float",
      "label": "GAE Lambda",
      "description": "Generalized Advantage Estimation lambda.",
      "min": 0.8,
      "max": 1.0,
      "default": 0.95
    },

    "entropy_coef": {
      "type": "float",
      "label": "Entropy Coefficient",
      "description": "Entropy regularization coefficient.",
      "min": 0.0,
      "max": 0.1,
      "default": 0.0
    },

    "value_loss_coef": {
      "type": "float",
      "label": "Value Loss Coefficient",
      "description": "Weight of the value function loss.",
      "min": 0.1,
      "max": 5.0,
      "default": 1.0
    },

    "max_grad_norm": {
      "type": "float",
      "label": "Max Gradient Norm",
      "description": "Maximum gradient norm for clipping.",
      "min": 0.1,
      "max": 10.0,
      "default": 1.0
    }
  }
}

